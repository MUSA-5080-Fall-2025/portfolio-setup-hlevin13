[
  {
    "objectID": "assignments/lab_2/Levin_Hope_Assignment2.html",
    "href": "assignments/lab_2/Levin_Hope_Assignment2.html",
    "title": "Assignment 2: Spatial Analysis and Visualization",
    "section": "",
    "text": "Learning Objectives: - Apply spatial operations to answer policy-relevant research questions - Integrate census demographic data with spatial analysis - Create publication-quality visualizations and maps - Work with spatial data from multiple sources - Communicate findings effectively for policy audiences"
  },
  {
    "objectID": "assignments/lab_2/Levin_Hope_Assignment2.html#assignment-overview",
    "href": "assignments/lab_2/Levin_Hope_Assignment2.html#assignment-overview",
    "title": "Assignment 2: Spatial Analysis and Visualization",
    "section": "",
    "text": "Learning Objectives: - Apply spatial operations to answer policy-relevant research questions - Integrate census demographic data with spatial analysis - Create publication-quality visualizations and maps - Work with spatial data from multiple sources - Communicate findings effectively for policy audiences"
  },
  {
    "objectID": "assignments/lab_2/Levin_Hope_Assignment2.html#part-1-healthcare-access-for-vulnerable-populations",
    "href": "assignments/lab_2/Levin_Hope_Assignment2.html#part-1-healthcare-access-for-vulnerable-populations",
    "title": "Assignment 2: Spatial Analysis and Visualization",
    "section": "Part 1: Healthcare Access for Vulnerable Populations",
    "text": "Part 1: Healthcare Access for Vulnerable Populations\n\nResearch Question\nWhich Pennsylvania counties have the highest proportion of vulnerable populations (elderly + low-income) living far from hospitals?\nYour analysis should identify counties that should be priorities for healthcare investment and policy intervention.\n\n\nRequired Analysis Steps\nComplete the following analysis, documenting each step with code and brief explanations:\n\nStep 1: Data Collection (5 points)\nLoad the required spatial data: - Pennsylvania county boundaries - Pennsylvania hospitals (from lecture data) - Pennsylvania census tracts\nYour Task:\n\n# Load required packages\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(tigris)\nlibrary(tidycensus)\nlibrary(scales)\nlibrary(patchwork)\nlibrary(here)\nlibrary(dplyr)\nlibrary(knitr)\nlibrary(ggplot2)\n\n# Census API key\ncensus_api_key(Sys.getenv(\"CENSUS_API_KEY\"), install = FALSE)\n\n# Load spatial data\npa_counties &lt;- st_read(\"data/Pennsylvania_County_Boundaries.shp\")\n\nReading layer `Pennsylvania_County_Boundaries' from data source \n  `/Users/hope/Documents/GitHub/portfolio-setup-hlevin13/assignments/lab_2/data/Pennsylvania_County_Boundaries.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 67 features and 19 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -8963377 ymin: 4825316 xmax: -8314404 ymax: 5201413\nProjected CRS: WGS 84 / Pseudo-Mercator\n\nhospitals &lt;- st_read(\"data/hospitals.geojson\")\n\nReading layer `hospitals' from data source \n  `/Users/hope/Documents/GitHub/portfolio-setup-hlevin13/assignments/lab_2/data/hospitals.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 223 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -80.49621 ymin: 39.75163 xmax: -74.86704 ymax: 42.13403\nGeodetic CRS:  WGS 84\n\ncensus_tracts &lt;- tracts(state = \"PA\", cb = TRUE)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |===                                                                   |   5%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |=======                                                               |  11%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |============                                                          |  18%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |==============                                                        |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |================                                                      |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |=======================                                               |  32%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |=========================                                             |  35%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |===============================                                       |  45%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |=================================                                     |  48%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |===================================                                   |  51%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |========================================                              |  58%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  59%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |============================================                          |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |===================================================                   |  72%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |===========================================================           |  85%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==============================================================        |  89%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |================================================================      |  91%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |====================================================================  |  98%\n  |                                                                            \n  |===================================================================== |  99%\n  |                                                                            \n  |======================================================================| 100%\n\n# Questions to answer:\nhospitals %&gt;%\n  group_by(FACILITY_N) %&gt;%\n  summarise(count = n())\n\nSimple feature collection with 222 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -80.49621 ymin: 39.75163 xmax: -74.86704 ymax: 42.13403\nGeodetic CRS:  WGS 84\n# A tibble: 222 × 3\n   FACILITY_N                                    count             geometry\n   &lt;chr&gt;                                         &lt;int&gt;          &lt;POINT [°]&gt;\n 1 ADVANCED SURGICAL HOSPITAL                        1 (-80.27907 40.15655)\n 2 AHN Canonsburg Hospital                           1 (-80.19077 40.24585)\n 3 AHN Emerus Westmoreland Neighborhood Hospital     1 (-79.60014 40.31084)\n 4 AHN Jefferson Hospital                            1 (-79.93342 40.31745)\n 5 AHN Saint Vincent Hospital                        1 (-80.07954 42.11131)\n 6 AHN-Allegheny General Hospital                    1 (-80.00332 40.45695)\n 7 AVENUES RECOVERY MEDICAL CENTER AT VALLEY FO…     1 (-75.36752 40.15866)\n 8 Albert Einstein Medical Center                    1 (-75.14335 40.03696)\n 9 Allegheny Health Network Wexford Hospital         1  (-80.0624 40.63554)\n10 Allegheny Valley Hospital                         1 (-79.73647 40.61824)\n# ℹ 212 more rows\n\ncensus_tracts %&gt;%\n  group_by(GEOID) %&gt;%\n  summarise(count = n())\n\nSimple feature collection with 3445 features and 2 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -80.51989 ymin: 39.7198 xmax: -74.68952 ymax: 42.26986\nGeodetic CRS:  NAD83\n# A tibble: 3,445 × 3\n   GEOID       count                                                    geometry\n   &lt;chr&gt;       &lt;int&gt;                                               &lt;POLYGON [°]&gt;\n 1 42001030101     1 ((-77.15032 40.04536, -77.15219 40.04152, -77.14124 40.036…\n 2 42001030103     1 ((-77.06828 39.97375, -77.06277 39.97149, -77.05646 39.968…\n 3 42001030104     1 ((-77.09913 39.94784, -77.0904 39.94587, -77.08214 39.9481…\n 4 42001030200     1 ((-77.23764 40.01404, -77.21936 40.00666, -77.21849 40.006…\n 5 42001030300     1 ((-77.42136 39.98129, -77.3946 39.96514, -77.38766 39.9589…\n 6 42001030400     1 ((-77.46961 39.91617, -77.46863 39.90723, -77.46876 39.903…\n 7 42001030500     1 ((-77.29438 39.93242, -77.2939 39.92694, -77.29242 39.9248…\n 8 42001030600     1 ((-77.22819 39.89023, -77.22149 39.88539, -77.22534 39.882…\n 9 42001030700     1 ((-77.18479 39.8121, -77.17674 39.80536, -77.1762 39.805, …\n10 42001030801     1 ((-77.02221 39.86435, -77.01868 39.85995, -77.00403 39.836…\n# ℹ 3,435 more rows\n\nst_crs(pa_counties)\n\nCoordinate Reference System:\n  User input: WGS 84 / Pseudo-Mercator \n  wkt:\nPROJCRS[\"WGS 84 / Pseudo-Mercator\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            MEMBER[\"World Geodetic System 1984 (G2296)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"Popular Visualisation Pseudo-Mercator\",\n        METHOD[\"Popular Visualisation Pseudo Mercator\",\n            ID[\"EPSG\",1024]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"False easting\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"easting (X)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"northing (Y)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Web mapping and visualisation.\"],\n        AREA[\"World between 85.06°S and 85.06°N.\"],\n        BBOX[-85.06,-180,85.06,180]],\n    ID[\"EPSG\",3857]]\n\nst_crs(hospitals)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\nst_crs(census_tracts)\n\nCoordinate Reference System:\n  User input: NAD83 \n  wkt:\nGEOGCRS[\"NAD83\",\n    DATUM[\"North American Datum 1983\",\n        ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4269]]\n\n\nQuestions to answer:\nHow many hospitals are in your dataset?\n\n223 hospitals\n\nHow many census tracts?\n\n3,445 census tracts\n\nWhat coordinate reference system is each dataset in? :\n\npa_counties: WGS 84 / Pseudo-Mercator EPSG: 3857\nhospitals: WGS 84 EPSG: 4326\ncensus_tracts: NAD83 EPSG: 4269\n\n\n\n\nStep 2: Get Demographic Data\nUse tidycensus to download tract-level demographic data for Pennsylvania.\nRequired variables: - Total population - Median household income - Population 65 years and over (you may need to sum multiple age categories)\nYour Task:\n\n# Get demographic data from ACS\npa_tract_data &lt;- get_acs(\n  geography = \"tract\",\n  state = \"Pennsylvania\",\n  variables = c(\n    total_population = \"B01003_001\", \n    median_income = \"B19013_001\",\n    over_65 = \"B01001_020\"),\n  survey = \"acs5\",\n  year = 2022,\n  output = \"wide\"\n)\n\n# Join to tract boundaries\ncensus_tracts &lt;- census_tracts %&gt;%\n  left_join(pa_tract_data, by = \"GEOID\")\n\n# Questions to answer:\npa_tract_data %&gt;%\n  filter(is.na(median_incomeE)) %&gt;%\n  count()\n\n# A tibble: 1 × 1\n      n\n  &lt;int&gt;\n1    63\n\nmedian(pa_tract_data$median_incomeE, na.rm = TRUE)\n\n[1] 70188\n\n\nQuestions to answer:\nWhat year of ACS data are you using?\n\n2022 ACS data\n\nHow many tracts have missing income data?\n\n63 tracts\n\nWhat is the median income across all PA census tracts?\n\n$70,188\n\n\n\n\nStep 3: Define Vulnerable Populations\nIdentify census tracts with vulnerable populations based on TWO criteria: 1. Low median household income (choose an appropriate threshold) 2. Significant elderly population (choose an appropriate threshold)\nYour Task:\n\n# Filter for vulnerable tracts based on your criteria\nincome_threshold &lt;- quantile (\n  census_tracts$median_incomeE, 0.25, na.rm = TRUE)\n# $55,924\n\ncensus_tracts &lt;- census_tracts %&gt;%\n  mutate(pct_over_65 = (over_65E / total_populationE) *100)\n\nage_threshold &lt;- quantile (\n  census_tracts$pct_over_65, 0.75, na.rm = TRUE)\n    \nvulnerable_pop &lt;- census_tracts %&gt;%\n  filter(\n    median_incomeE &lt; income_threshold,\n    pct_over_65 &gt; age_threshold\n  )\n\nvulnerable_pop &lt;- vulnerable_pop %&gt;%\n  mutate(\n    vulnerable = median_incomeE &lt; income_threshold & pct_over_65 &gt; age_threshold\n  )\n\nQuestions to answer:\nWhat income threshold did you choose and why?\n\nMy income threshold is the bottom 25%, or $55,924. By going with a quantile approach, I was able to determine the cutoff in context of the entire state.\n\nWhat elderly population threshold did you choose and why?\n\nAgain, I went with a quantile approach for contextual understanding. However, I choose the top 25% as I was interested in seeing tracts with large elderly populations.\n\nHow many tracts meet your vulnerability criteria?\n\n168 tracts meet both criterias.\n\nWhat percentage of PA census tracts are considered vulnerable by your definition?\n\n4.87% of tracts.\n\n\n\n\nStep 4: Calculate Distance to Hospitals\nFor each vulnerable tract, calculate the distance to the nearest hospital.\nYour Task:\n\n# Transform to appropriate projected CRS\nvulnerable_pop &lt;- st_transform(vulnerable_pop, crs = 3365)\n\nhospitals &lt;- st_transform(hospitals, crs = 3365)\n\n# Calculate distance from each tract centroid to nearest hospital\ntract_centroid &lt;- st_centroid(vulnerable_pop)\n\ndistance_matrix &lt;- st_distance(tract_centroid, hospitals)\n\nvulnerable_pop &lt;- vulnerable_pop %&gt;%\n  mutate(\n    hospital_dis = apply(distance_matrix, 1, min),\n    hospital_miles = as.numeric(hospital_dis) / 1609.34)\n\n# Questions to answer\nvulnerable_pop %&gt;%\n  summarise(\n    avg_distance = mean(hospital_miles, na.rm = TRUE),\n    max_distance = max(hospital_miles, na.rm = TRUE),\n    over_15 = sum(hospital_miles &gt; 15, na.rm = TRUE)\n)\n\nSimple feature collection with 1 feature and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 1204220 ymin: 145044.8 xmax: 2727730 ymax: 1029901\nProjected CRS: NAD83(HARN) / Pennsylvania South (ftUS)\n  avg_distance max_distance over_15                       geometry\n1     13.46201     62.85519      47 MULTIPOLYGON (((1337166 245...\n\n\nRequirements: - Use an appropriate projected coordinate system for Pennsylvania - Calculate distances in miles - Explain why you chose your projection\n\nI chose Pennsylvania State Plane South, as it is the projection that I am most comfortable mapping with.\n\nQuestions to answer:\nWhat is the average distance to the nearest hospital for vulnerable tracts?\n\nThe average distance to the nearest tract for vulnerable tracts is 13.5 miles.\n\nWhat is the maximum distance?\n\nThe maximum distance is 62.9 miles.\n\nHow many vulnerable tracts are more than 15 miles from the nearest hospital?\n\n47 tracts are more than 15 miles away from the nearest hospital.\n\n\n\n\nStep 5: Identify Underserved Areas\nDefine “underserved” as vulnerable tracts that are more than 15 miles from the nearest hospital.\nYour Task:\n\n# Create underserved variable\nvulnerable_pop &lt;- vulnerable_pop %&gt;%\n  mutate(\n    underserved = hospital_miles &gt; 15 & median_incomeE &lt; income_threshold & pct_over_65 &gt; age_threshold\n  )\n\n# Questions to answer\nvulnerable_pop %&gt;%\n  summarise(\n    underserved_count = sum(underserved, na.rm = TRUE),\n    total_tracts = n (),\n    underserved_pct = (underserved_count/total_tracts)*100\n  )\n\nSimple feature collection with 1 feature and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 1204220 ymin: 145044.8 xmax: 2727730 ymax: 1029901\nProjected CRS: NAD83(HARN) / Pennsylvania South (ftUS)\n  underserved_count total_tracts underserved_pct                       geometry\n1                47          168        27.97619 MULTIPOLYGON (((1337166 245...\n\n\nQuestions to answer:\nHow many tracts are underserved?\n\n47 tracts are underserved.\n\nWhat percentage of vulnerable tracts are underserved?\n\nRoughly 28% of tracts are underserved.\n\nDoes this surprise you? Why or why not?\n\nSomewhat…having gone to college in upstate New York, I’m well aware of healthcare access disparities in rural America. However, I was anticipating the number to be much lower, around 20-25%. Shocking that such a high barrier exists given the supposed advancements in this country.\n\n\n\n\nStep 6: Aggregate to County Level\nUse spatial joins and aggregation to calculate county-level statistics about vulnerable populations and hospital access.\nYour Task:\n\n# Spatial join tracts to counties\npa_counties &lt;- st_transform(pa_counties, crs = 3365)\nvulnerable_pop &lt;- st_transform(vulnerable_pop, crs = 3365)\n\ntracts_with_counties &lt;- vulnerable_pop %&gt;%\n  st_join(pa_counties %&gt;% select(COUNTY_NAM))\n\n# Aggregate statistics by county\ncounty_stats &lt;- tracts_with_counties %&gt;%\n  st_drop_geometry() %&gt;%\n  group_by(COUNTY_NAM) %&gt;%\n  summarise(\n    total_tracts = n(),\n    vulnerable_num = sum(vulnerable, na.rm = TRUE),\n    underserved_num = sum(underserved, na.rm =TRUE),\n    pct_underserved = (underserved_num/vulnerable_num)*100,\n    hosp_dist = mean(hospital_miles, na.rm = TRUE),\n    total = sum (total_populationE, na.rm = TRUE)\n  ) %&gt;%\n  ungroup()\n\nRequired county-level statistics: - Number of vulnerable tracts - Number of underserved tracts\n- Percentage of vulnerable tracts that are underserved - Average distance to nearest hospital for vulnerable tracts - Total vulnerable population\nQuestions to answer:\nWhich 5 counties have the highest percentage of underserved vulnerable tracts?\n\nI found that 21 counties share the same percentage of underserved vulnerable tracts - Armstrong, Cameron, Clarion, Clinton, Elk, Forest, Franklin, Fulton, Greene, Huntingdon, Indiana, Jefferson, Juniata, Lebanon, McKean, Monroe, Norththumberland, Perry, Potter, Somerset, and Tioga.\n\nWhich counties have the most vulnerable people living far from hospitals?\n\nThe top 5 counties of vulnerable people living from hospitals are 1. Monroe (58 miles), Perry, Franklin, Juniata, 5. Forest (50 miles).\n\nAre there any patterns in where underserved counties are located?\n\nMany of these counties are clustered in the Northwest, Central, and Southeast Pennsylvania.\n\n\n\n\nStep 7: Create Summary Table\nCreate a professional table showing the top 10 priority counties for healthcare investment.\nYour Task:\n\n# Create and format priority counties table\npriority_counties &lt;- county_stats %&gt;%\n  arrange(desc(hosp_dist)) %&gt;%\n    slice(1:10) %&gt;%\n  select(COUNTY_NAM, total_tracts, total, pct_underserved, hosp_dist)\n\nkable(priority_counties,\n      col.names = c(\"County\", \"Vulnerable Tracts\", \"Total Population\", \"Underserved Vulnerable Tracts (%)\", \"Distance to Nearest Hospital (mi)\"),\n      caption = \"Top 10 Priority Counties for Healthcare Investment\",\n      format.args = list(big.mark = \",\")\n)\n\n\nTop 10 Priority Counties for Healthcare Investment\n\n\n\n\n\n\n\n\n\nCounty\nVulnerable Tracts\nTotal Population\nUnderserved Vulnerable Tracts (%)\nDistance to Nearest Hospital (mi)\n\n\n\n\nMONROE\n1\n1,299\n100\n58.02058\n\n\nPERRY\n2\n5,800\n100\n57.52312\n\n\nFRANKLIN\n1\n1,782\n100\n52.19105\n\n\nJUNIATA\n1\n1,782\n100\n52.19105\n\n\nFOREST\n2\n4,406\n100\n50.03962\n\n\nCLARION\n2\n4,750\n100\n47.65747\n\n\nSOMERSET\n1\n2,138\n100\n46.97646\n\n\nTIOGA\n2\n6,865\n100\n46.44334\n\n\nHUNTINGDON\n2\n5,111\n100\n43.53532\n\n\nNORTHUMBERLAND\n7\n21,415\n100\n43.15381\n\n\n\n\n\nRequirements: - Use knitr::kable() or similar for formatting - Include descriptive column names - Format numbers appropriately (commas for population, percentages, etc.) - Add an informative caption - Sort by priority (you decide the metric)"
  },
  {
    "objectID": "assignments/lab_2/Levin_Hope_Assignment2.html#part-2-comprehensive-visualization",
    "href": "assignments/lab_2/Levin_Hope_Assignment2.html#part-2-comprehensive-visualization",
    "title": "Assignment 2: Spatial Analysis and Visualization",
    "section": "Part 2: Comprehensive Visualization",
    "text": "Part 2: Comprehensive Visualization\nUsing the skills from Week 3 (Data Visualization), create publication-quality maps and charts.\n\nMap 1: County-Level Choropleth\nCreate a choropleth map showing healthcare access challenges at the county level.\nYour Task:\n\n# Create county-level access map\ncounty_map &lt;- pa_counties %&gt;%\n  st_transform(crs = st_crs(vulnerable_pop)) %&gt;%\n  left_join(county_stats, by = \"COUNTY_NAM\")\n\nhospitals &lt;- st_transform(hospitals, crs = 3365)\n\nggplot() +\n  geom_sf(data = county_map, \n          aes(fill = pct_underserved), \n          color = \"black\", size = .25) +\n  geom_sf(data = hospitals,\n          color = \"white\",\n          size = 1) +\n  scale_fill_viridis_c(\n    name = \"Percent Underserved\",\n    option = \"magma\"\n  ) +\n  labs(\n    title = \"Healthcare Disparity Across Pennsylvania\",\n    subtitle = \"Percent of vulnerable census tracts underserved by county\",\n    caption = \"Source: ACS 2022 5-Year Estimates\"\n  ) +\n  theme_void()\n\n\n\n\n\n\n\n\nRequirements: - Fill counties by percentage of vulnerable tracts that are underserved - Include hospital locations as points - Use an appropriate color scheme - Include clear title, subtitle, and caption - Use theme_void() or similar clean theme - Add a legend with formatted labels\n\n\n\nMap 2: Detailed Vulnerability Map\nCreate a map highlighting underserved vulnerable tracts.\nYour Task:\n\n# Create detailed tract-level map\nvulnerable_pop &lt;- vulnerable_pop %&gt;%\n  mutate(\n    underserved_flag = ifelse (underserved == TRUE, \"Underserved\", \"Other\")\n  )\n\nunique(vulnerable_pop$underserved_flag)\n\n[1] \"Underserved\" \"Other\"      \n\nggplot () +\n  geom_sf(data = vulnerable_pop,\n          aes(fill = underserved_flag),\n          color = \"grey\")+\n  geom_sf(data = pa_counties,\n          fill = NA,\n          color = \"black\",\n          size = 0.5) +\n  geom_sf(data = hospitals,\n          size = 2,\n          shape = 21,\n          fill = \"cornflowerblue\")+\n  scale_fill_manual(values = c(\"Underserved\" = \"orchid\", \n                                  \"Other\" = \"darkorange\"),\n                    name = \"Vulnerability Status\")+\n  labs(\n    title = \"Underserved Vulnerable Tracts in Pennsylvania\",\n    subtitle = \"Census Tracts with Limited Access to Hospitals\",\n    caption = \"Source: ACS 2022 5-Year Estimates\"\n  )+\n  theme_void()\n\n\n\n\n\n\n\n\nRequirements: - Show underserved vulnerable tracts in a contrasting color - Include county boundaries for context - Show hospital locations - Use appropriate visual hierarchy (what should stand out?) - Include informative title and subtitle\n\n\n\nChart: Distribution Analysis\nCreate a visualization showing the distribution of distances to hospitals for vulnerable populations.\nYour Task:\n\n# Create distribution visualization\nggplot(vulnerable_pop, aes(x = hospital_miles)) +\n         geom_histogram(bins = 15, fill = \"steelblue\", alpha = 0.7) +\n         labs(\n           title = \"Distribution of Distances to Nearest Hospital in Pennsylvania\",\n           subtitle = \"A clear disparity exists with some census tracts being 50+ miles from the nearest hospital\",\n           x = \"Distance to Nearest Hospital (mi)\",\n           y = \"Number of Tracts\",\n           caption = \"Source: ACS 2022 5-Year Estimates\"\n         )+\n         theme_minimal()\n\n\n\n\n\n\n\n\nSuggested chart types: - Histogram or density plot of distances - Box plot comparing distances across regions - Bar chart of underserved tracts by county - Scatter plot of distance vs. vulnerable population size\nRequirements: - Clear axes labels with units - Appropriate title - Professional formatting - Brief interpretation (1-2 sentences as a caption or in text)"
  },
  {
    "objectID": "assignments/lab_2/Levin_Hope_Assignment2.html#part-3-bring-your-own-data-analysis",
    "href": "assignments/lab_2/Levin_Hope_Assignment2.html#part-3-bring-your-own-data-analysis",
    "title": "Assignment 2: Spatial Analysis and Visualization",
    "section": "Part 3: Bring Your Own Data Analysis",
    "text": "Part 3: Bring Your Own Data Analysis\nChoose your own additional spatial dataset and conduct a supplementary analysis.\n\nChallenge Options\nChoose ONE of the following challenge exercises, or propose your own research question using OpenDataPhilly data (https://opendataphilly.org/datasets/).\nNote these are just loose suggestions to spark ideas - follow or make your own as the data permits and as your ideas evolve. This analysis should include bringing in your own dataset, ensuring the projection/CRS of your layers align and are appropriate for the analysis (not lat/long or geodetic coordinate systems). The analysis portion should include some combination of spatial and attribute operations to answer a relatively straightforward question\n\n\nEducation & Youth Services\nOption A: Educational Desert Analysis - Data: Schools, Libraries, Recreation Centers, Census tracts (child population) - Question: “Which neighborhoods lack adequate educational infrastructure for children?” - Operations: Buffer schools/libraries (0.5 mile walking distance), identify coverage gaps, overlay with child population density - Policy relevance: School district planning, library placement, after-school program siting\nOption B: School Safety Zones - Data: Schools, Crime Incidents, Bike Network - Question: “Are school zones safe for walking/biking, or are they crime hotspots?” - Operations: Buffer schools (1000ft safety zone), spatial join with crime incidents, assess bike infrastructure coverage - Policy relevance: Safe Routes to School programs, crossing guard placement\n\n\n\nEnvironmental Justice\nOption C: Green Space Equity - Data: Parks, Street Trees, Census tracts (race/income demographics) - Question: “Do low-income and minority neighborhoods have equitable access to green space?” - Operations: Buffer parks (10-minute walk = 0.5 mile), calculate tree canopy or park acreage per capita, compare by demographics - Policy relevance: Climate resilience, environmental justice, urban forestry investment —\n\n\nPublic Safety & Justice\nOption D: Crime & Community Resources - Data: Crime Incidents, Recreation Centers, Libraries, Street Lights - Question: “Are high-crime areas underserved by community resources?” - Operations: Aggregate crime counts to census tracts or neighborhoods, count community resources per area, spatial correlation analysis - Policy relevance: Community investment, violence prevention strategies —\n\n\nInfrastructure & Services\nOption E: Polling Place Accessibility - Data: Polling Places, SEPTA stops, Census tracts (elderly population, disability rates) - Question: “Are polling places accessible for elderly and disabled voters?” - Operations: Buffer polling places and transit stops, identify vulnerable populations, find areas lacking access - Policy relevance: Voting rights, election infrastructure, ADA compliance\n\n\n\nHealth & Wellness\nOption F: Recreation & Population Health - Data: Recreation Centers, Playgrounds, Parks, Census tracts (demographics) - Question: “Is lack of recreation access associated with vulnerable populations?” - Operations: Calculate recreation facilities per capita by neighborhood, buffer facilities for walking access, overlay with demographic indicators - Policy relevance: Public health investment, recreation programming, obesity prevention\n\n\n\nEmergency Services\nOption G: EMS Response Coverage - Data: Fire Stations, EMS stations, Population density, High-rise buildings - Question: “Are population-dense areas adequately covered by emergency services?” - Operations: Create service area buffers (5-minute drive = ~2 miles), assess population coverage, identify gaps in high-density areas - Policy relevance: Emergency preparedness, station siting decisions\n\n\n\nArts & Culture\nOption H: Cultural Asset Distribution - Data: Public Art, Museums, Historic sites/markers, Neighborhoods - Question: “Do all neighborhoods have equitable access to cultural amenities?” - Operations: Count cultural assets per neighborhood, normalize by population, compare distribution across demographic groups - Policy relevance: Cultural equity, tourism, quality of life, neighborhood identity\n\n\n\n\nData Sources\nOpenDataPhilly: https://opendataphilly.org/datasets/ - Most datasets available as GeoJSON, Shapefile, or CSV with coordinates - Always check the Metadata for a data dictionary of the fields.\nAdditional Sources: - Pennsylvania Open Data: https://data.pa.gov/ - Census Bureau (via tidycensus): Demographics, economic indicators, commute patterns - TIGER/Line (via tigris): Geographic boundaries\n\n\nRecommended Starting Points\nIf you’re feeling confident: Choose an advanced challenge with multiple data layers. If you are a beginner, choose something more manageable that helps you understand the basics\nIf you have a different idea: Propose your own question! Just make sure: - You can access the spatial data - You can perform at least 2 spatial operations\n\n\nYour Analysis\nYour Task:\n\nFind and load additional data\n\nDocument your data source\nCheck and standardize the CRS\nProvide basic summary statistics\n\n\n\n# Load your additional dataset\nschools &lt;- st_read(\"step_7_data/Schools.geojson\")\n\nReading layer `Schools' from data source \n  `/Users/hope/Documents/GitHub/portfolio-setup-hlevin13/assignments/lab_2/step_7_data/Schools.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 495 features and 14 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -75.2665 ymin: 39.90781 xmax: -74.97057 ymax: 40.12974\nGeodetic CRS:  WGS 84\n\n  # OpenDataPhilly: unknown\n\ncrime &lt;- st_read(\"step_7_data/crime_2022/incidents_part1_part2.shp\")\n\nReading layer `incidents_part1_part2' from data source \n  `/Users/hope/Documents/GitHub/portfolio-setup-hlevin13/assignments/lab_2/step_7_data/crime_2022/incidents_part1_part2.shp' \n  using driver `ESRI Shapefile'\nreplacing null geometries with empty geometries\nSimple feature collection with 151197 features and 13 fields (with 890 geometries empty)\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -75.2753 ymin: 39.87731 xmax: -74.95981 ymax: 40.13646\nGeodetic CRS:  WGS 84\n\n  # OpenDataPhilly; 2022\n\nschools &lt;- st_transform(schools, crs = 3365)\ncrime &lt;- st_transform(crime, crs = 3365)\n\nsummary(schools)\n\n      aun              school_num   location_id        school_name       \n Min.   :100510000   Min.   :3445   Length:495         Length:495        \n 1st Qu.:126515001   1st Qu.:3752   Class :character   Class :character  \n Median :126515001   Median :6527   Mode  :character   Mode  :character  \n Mean   :163032553   Mean   :5776                                        \n 3rd Qu.:226511157   3rd Qu.:7664                                        \n Max.   :326517786   Max.   :8493                                        \n NA's   :51          NA's   :208                                         \n school_name_label  street_address       zip_code         phone_number      \n Length:495         Length:495         Length:495         Length:495        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n grade_level         grade_org           enrollment          type      \n Length:495         Length:495         Min.   :   1.0   Min.   :1.000  \n Class :character   Class :character   1st Qu.: 270.0   1st Qu.:1.000  \n Mode  :character   Mode  :character   Median : 446.0   Median :1.000  \n                                       Mean   : 548.5   Mean   :1.768  \n                                       3rd Qu.: 656.0   3rd Qu.:3.000  \n                                       Max.   :3467.0   Max.   :3.000  \n                                       NA's   :162                     \n type_specific         objectid              geometry  \n Length:495         Min.   :  1.0   POINT        :495  \n Class :character   1st Qu.:124.5   epsg:3365    :  0  \n Mode  :character   Median :248.0   +proj=lcc ...:  0  \n                    Mean   :248.0                      \n                    3rd Qu.:371.5                      \n                    Max.   :495.0                      \n                                                       \n\nsummary(crime)\n\n    objectid          dc_dist              psa              dispatch_d        \n Min.   :  155179   Length:151197      Length:151197      Min.   :2022-01-01  \n 1st Qu.:  197137   Class :character   Class :character   1st Qu.:2022-04-13  \n Median : 1125907   Mode  :character   Mode  :character   Median :2022-07-10  \n Mean   :  973124                                         Mean   :2022-07-07  \n 3rd Qu.: 1167711                                         3rd Qu.:2022-10-03  \n Max.   :32643386                                         Max.   :2022-12-31  \n                                                                              \n  dispatch_1         dispatch_t             hour           dc_key         \n Length:151197      Length:151197      Min.   : 0.00   Min.   :2.010e+11  \n Class :character   Class :character   1st Qu.:10.00   1st Qu.:2.022e+11  \n Mode  :character   Mode  :character   Median :14.00   Median :2.022e+11  \n                                       Mean   :13.31   Mean   :2.022e+11  \n                                       3rd Qu.:18.00   3rd Qu.:2.022e+11  \n                                       Max.   :23.00   Max.   :2.023e+11  \n                                       NA's   :2                          \n  location_b         ucr_genera         text_gener           point_x      \n Length:151197      Length:151197      Length:151197      Min.   :-75.28  \n Class :character   Class :character   Class :character   1st Qu.:-75.19  \n Mode  :character   Mode  :character   Mode  :character   Median :-75.16  \n                                                          Mean   :-75.15  \n                                                          3rd Qu.:-75.12  \n                                                          Max.   :-74.96  \n                                                          NA's   :890     \n    point_y               geometry     \n Min.   :39.88   POINT        :151197  \n 1st Qu.:39.96   epsg:3365    :     0  \n Median :39.99   +proj=lcc ...:     0  \n Mean   :39.99                         \n 3rd Qu.:40.03                         \n Max.   :40.14                         \n NA's   :890                           \n\n\nQuestions to answer:\nWhat dataset did you choose and why?\n\nI chose to focus on the school safety zones, because I live near a school and was curious about the chance of them being crime hotspots!\n\nWhat is the data source and date?\n\nEverything was sourced from OpenDataPhilly. I was unable to find the sourcing date for the school data, however, the crime data comes from 2022 (wanted to match it with the ACS data I pulled earlier).\n\nHow many features does it contain?\n\nThere are 2 features.\n\nWhat CRS is it in? Did you need to transform it?\n\nI transformed everything to be in NAD83 Pennsylvania South.\n\n\n\nPose a research question\n\nWrite a clear research statement that your analysis will answer.\nExamples: - “Do vulnerable tracts have adequate public transit access to hospitals?” - “Are EMS stations appropriately located near vulnerable populations?” - “Do areas with low vehicle access have worse hospital access?”\n“How much crime occurs near Philadelphia schools?”\n\n\nConduct spatial analysis\n\nUse at least TWO spatial operations to answer your research question.\nRequired operations (choose 2+): - Buffers - Spatial joins - Spatial filtering with predicates - Distance calculations - Intersections or unions - Point-in-polygon aggregation\nYour Task:\n\n# Your spatial analysis\n\n# Set CRS\nschools &lt;- st_transform(schools, crs = 3365)\ncrime &lt;- st_transform(crime, crs = 3365)\n\n# Create 1000ft buffers around each school to represent the safety zones\nschool_buffer &lt;- schools %&gt;%\n  st_buffer (dist = 1000) %&gt;%\n  st_union() %&gt;%\n  st_as_sf()\n\n# Determine crimes within buffers/safety zones\ncrime_near_school &lt;- st_join(\n  crime, school_buffer,\n  join = st_within, left = FALSE\n)\n\n# Count total crimes and the number that happened near schools\ncrime_total &lt;- nrow(crime)\ncrime_schoolzone &lt;- nrow(crime_near_school)\n\n# Find percent of crimes near schools\ncrime_percent &lt;- round((crime_schoolzone / crime_total) *100, 2)\n\n# Results\ncat(\"Total Crimes:\", crime_total, \"\\n\")\n\nTotal Crimes: 151197 \n\ncat(\"Crimes within 1000ft of schools:\", crime_schoolzone, \"\\n\")\n\nCrimes within 1000ft of schools: 74198 \n\ncat(\"Percent of crimes within 1000ft of schools:\", crime_percent, \"%\\n\")\n\nPercent of crimes within 1000ft of schools: 49.07 %\n\n# Map\nggplot() +\n  geom_sf(data = crime,\n          color = \"tomato\",\n          size = .5,\n          alpha = .1) +\n   geom_sf(data = school_buffer,\n          fill = \"navyblue\",\n          alpha = .8) +\n  geom_sf(data = schools,\n          color = \"deepskyblue3\",\n          size = 1) +\n  labs(\n    title = \"School Safety Zones and Crime in Philadelphia, PA\",\n    subtitle = \"1000ft Safety Buffer Around Schools and Locations of Crime\",\n    caption = \"Source: OpenDataPhilly\") +\n  theme_void()\n\n\n\n\n\n\n\n\nAnalysis requirements: - Clear code comments explaining each step - Appropriate CRS transformations - Summary statistics or counts - At least one map showing your findings - Brief interpretation of results (3-5 sentences)\nYour interpretation:\nTotal Crimes: 151,197 Crimes Within 1000ft of schools: 74,198 Percent of Crimes Within 1000ft of Schools: 49.07%\nConsidering 49% of crimes occur within 1000ft of schools, there is a clear need for additional measures to ensure that Philadelphia’s youth are kept safe. If speeding is an issue, then perhaps crossing guards can be kept on for additional hours or in farther places. If its a bigger issue - like murder or drug trafficking - then police presence! However, because the dataset does not report the type of crime committed, further investigation is needed to determine what is needed."
  },
  {
    "objectID": "assignments/lab_2/Levin_Hope_Assignment2.html#finally---a-few-comments-about-your-incorporation-of-feedback",
    "href": "assignments/lab_2/Levin_Hope_Assignment2.html#finally---a-few-comments-about-your-incorporation-of-feedback",
    "title": "Assignment 2: Spatial Analysis and Visualization",
    "section": "Finally - A few comments about your incorporation of feedback!",
    "text": "Finally - A few comments about your incorporation of feedback!\nTake a few moments to clean up your markdown document and then write a line or two or three about how you may have incorporated feedback that you recieved after your first assignment.\nHopefully I hid my API key this time! I’ve run into a few issues with that… from GitHub emailing me about it being available for anyone to access to Zhanchao alerting me on my last assignment. Also, I tried to format my data better and add comments throughout."
  },
  {
    "objectID": "assignments/lab_2/Levin_Hope_Assignment2.html#submission-requirements",
    "href": "assignments/lab_2/Levin_Hope_Assignment2.html#submission-requirements",
    "title": "Assignment 2: Spatial Analysis and Visualization",
    "section": "Submission Requirements",
    "text": "Submission Requirements\nWhat to submit:\n\nRendered HTML document posted to your course portfolio with all code, outputs, maps, and text\n\nUse embed-resources: true in YAML so it’s a single file\nAll code should run without errors\nAll maps and charts should display correctly\n\n\nFile naming: LastName_FirstName_Assignment2.html and LastName_FirstName_Assignment2.qmd"
  }
]